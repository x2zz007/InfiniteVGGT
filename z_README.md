# InfiniteVGGT: æµå¼å¤„ç†æ ¸å¿ƒåˆ›æ–°è¯¦ç»†åˆ†æ

## ğŸ“‹ ç›®å½•
1. [æ ¸å¿ƒé—®é¢˜](#æ ¸å¿ƒé—®é¢˜)
2. [åˆ›æ–°æ¶æ„](#åˆ›æ–°æ¶æ„)
3. [æµå¼å¤„ç†æœºåˆ¶](#æµå¼å¤„ç†æœºåˆ¶)
4. [å…³é”®æŠ€æœ¯](#å…³é”®æŠ€æœ¯)
5. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)

---

## æ ¸å¿ƒé—®é¢˜

### ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§

ä¼ ç»Ÿçš„å¤šè§†å›¾3Dé‡å»ºæ–¹æ³•ï¼ˆå¦‚VGGTï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

| é—®é¢˜ | æè¿° | å½±å“ |
|------|------|------|
| **å†…å­˜æº¢å‡º** | å¤„ç†é•¿åºåˆ—æ—¶ï¼ŒKVç¼“å­˜çº¿æ€§å¢é•¿ | æ— æ³•å¤„ç†æ— é™é•¿è§†é¢‘æµ |
| **è®¡ç®—å¤æ‚åº¦** | å…¨å±€æ³¨æ„åŠ›å¤æ‚åº¦ä¸º $O(n^2)$ | å¤„ç†é€Ÿåº¦éšå¸§æ•°æŒ‡æ•°å¢é•¿ |
| **ä½ç½®ç¼–ç å¤±æ•ˆ** | å›ºå®šä½ç½®ç¼–ç æ— æ³•é€‚åº”åŠ¨æ€åºåˆ— | é•¿åºåˆ—æ€§èƒ½ä¸¥é‡ä¸‹é™ |
| **ä¿¡æ¯å†—ä½™** | æ‰€æœ‰å†å²å¸§ç­‰æƒé‡å¤„ç† | æµªè´¹è®¡ç®—èµ„æº |

### InfiniteVGGTçš„ç›®æ ‡

$$\text{Goal}: \text{Process}(I_1, I_2, \ldots, I_\infty) \rightarrow \text{Stable 3D Geometry}$$

å…¶ä¸­ $I_t$ æ˜¯ç¬¬ $t$ å¸§å›¾åƒï¼Œéœ€è¦æ»¡è¶³ï¼š
- âœ… æ— é™é•¿åºåˆ—å¤„ç†èƒ½åŠ›
- âœ… æ’å®šå†…å­˜å ç”¨
- âœ… å®æ—¶æ¨ç†é€Ÿåº¦
- âœ… ç¨³å®šçš„å‡ ä½•ä¼°è®¡

---

## åˆ›æ–°æ¶æ„

### 1. åŒæµäº¤æ›¿æ³¨æ„åŠ›æœºåˆ¶

InfiniteVGGTé‡‡ç”¨**äº¤æ›¿æ³¨æ„åŠ›ï¼ˆAlternating Attentionï¼‰**æ¶æ„ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Input: [B, S, 3, H, W]                      â”‚
â”‚         (Batch, Sequence, Channels, Height, Width) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
    â”‚ Frame  â”‚            â”‚ Global  â”‚
    â”‚Attention           â”‚Attentionâ”‚
    â”‚(Within)            â”‚(Cross)  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Concatenate Features   â”‚
        â”‚  [B, S, P, 2C]          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Prediction Heads      â”‚
        â”‚  (Camera/Depth/Points)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ•°å­¦è¡¨ç¤º**ï¼š

$$\text{Frame Attn}: \text{Attn}(Q_s, K_s, V_s) = \text{softmax}\left(\frac{Q_s K_s^T}{\sqrt{d}}\right)V_s$$

å…¶ä¸­ $s$ è¡¨ç¤ºå•ä¸ªå¸§å†…çš„æ³¨æ„åŠ›ã€‚

$$\text{Global Attn}: \text{Attn}(Q, K, V) = \text{softmax}\left(\frac{Q K^T}{\sqrt{d}} + M_{\text{causal}}\right)V$$

å…¶ä¸­ $M_{\text{causal}}$ æ˜¯å› æœæ©ç ï¼Œé˜²æ­¢çœ‹åˆ°æœªæ¥å¸§ã€‚

### 2. ç‰¹æ®Šä»¤ç‰Œè®¾è®¡

```python
# æ¥è‡ª aggregator.py ç¬¬125-129è¡Œ
self.camera_token = nn.Parameter(torch.randn(1, 2, 1, embed_dim))
self.register_token = nn.Parameter(torch.randn(1, 2, num_register_tokens, embed_dim))
self.patch_start_idx = 1 + num_register_tokens
```

**ä»¤ç‰Œç»“æ„**ï¼š

$$\text{Tokens} = [\text{Camera}_{\text{query}}, \text{Register}, \text{Patches}]$$

- **Camera Token**: 2ä¸ªä½ç½®ï¼ˆæŸ¥è¯¢å¸§1ä¸ªï¼Œå…¶ä»–å¸§1ä¸ªï¼‰
- **Register Token**: 4ä¸ªå¯å­¦ä¹ ä»¤ç‰Œï¼Œç”¨äºä¿¡æ¯èšåˆ
- **Patch Token**: å›¾åƒå—ä»¤ç‰Œï¼Œ$P = (H/14) \times (W/14)$

---

## æµå¼å¤„ç†æœºåˆ¶

### 1. åŠ¨æ€KVç¼“å­˜ç®¡ç†

**æ ¸å¿ƒåˆ›æ–°**ï¼šä½¿ç”¨**ä»¤ç‰Œé©±é€ç­–ç•¥**è€Œéç®€å•çš„FIFO

```python
# æ¥è‡ª attention.py ç¬¬48-93è¡Œ
def eviction(self, k, v, cache_budget, num_anchor_tokens):
    """
    åŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„æ™ºèƒ½é©±é€
    """
    if N <= cache_budget:
        return k, v  # ç¼“å­˜æœªæ»¡
    
    # åˆ†ç¦»é”šç‚¹ä»¤ç‰Œå’Œå€™é€‰ä»¤ç‰Œ
    anchor_k, candidate_k = k.split([num_anchor_tokens, N - num_anchor_tokens])
    
    # è®¡ç®—å€™é€‰ä»¤ç‰Œä¸å¹³å‡å‘é‡çš„ç›¸ä¼¼åº¦
    candidate_k_norm = F.normalize(candidate_k, p=2, dim=-1)
    mean_vector = torch.mean(candidate_k_norm, dim=2, keepdim=True)
    scores = torch.sum(candidate_k_norm * mean_vector, dim=-1)
    
    # ä¿ç•™ç›¸ä¼¼åº¦æœ€ä½çš„ä»¤ç‰Œï¼ˆæœ€å…·å¤šæ ·æ€§ï¼‰
    _, top_indices = torch.topk(-scores, k=num_to_keep)
    
    return final_k, final_v, avg_scores
```

**é©±é€ç­–ç•¥çš„æ•°å­¦åŸç†**ï¼š

$$\text{Diversity Score} = 1 - \text{Similarity}(k_i, \bar{k})$$

$$\text{Keep} = \arg\text{topk}_{\text{high}}(\text{Diversity Score}, B)$$

å…¶ä¸­ $\bar{k}$ æ˜¯æ‰€æœ‰å€™é€‰ä»¤ç‰Œçš„å¹³å‡å€¼ã€‚

### 2. åŠ¨æ€é¢„ç®—åˆ†é…

```python
# æ¥è‡ª aggregator.py ç¬¬386-396è¡Œ
def _calculate_dynamic_budgets(self, total_budget):
    """
    æ ¹æ®å¤šæ ·æ€§åˆ†æ•°åŠ¨æ€åˆ†é…é¢„ç®—
    """
    diversity_scores = 1.0 - self.last_scores
    scaled_scores = diversity_scores / 0.5
    proportions = torch.softmax(scaled_scores, dim=0)
    budgets = proportions * total_budget
    return budgets.int()
```

**é¢„ç®—åˆ†é…å…¬å¼**ï¼š

$$B_i = \frac{\exp(\text{Diversity}_i / \tau)}{\sum_j \exp(\text{Diversity}_j / \tau)} \times B_{\text{total}}$$

å…¶ä¸­ $\tau = 0.5$ æ˜¯æ¸©åº¦å‚æ•°ã€‚

### 3. å› æœæ©ç æœºåˆ¶

```python
# æ¥è‡ª aggregator.py ç¬¬357-360è¡Œ
frame_ids = torch.arange(L, device=tokens.device) // P
future_frame = frame_ids.unsqueeze(1) < frame_ids.unsqueeze(0)
attn_mask = future_frame.to(tokens.dtype) * torch.finfo(tokens.dtype).min
```

**å› æœæ©ç çŸ©é˜µ**ï¼š

$$M_{\text{causal}}[i,j] = \begin{cases} 
0 & \text{if } i \geq j \text{ (can attend)} \\
-\infty & \text{if } i < j \text{ (cannot attend future)}
\end{cases}$$

---

## å…³é”®æŠ€æœ¯

### 1. æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰

```python
# æ¥è‡ª aggregator.py ç¬¬74-76è¡Œ
self.rope = RotaryPositionEmbedding2D(frequency=rope_freq) if rope_freq > 0 else None
self.position_getter = PositionGetter() if self.rope is not None else None
```

**RoPEçš„ä¼˜åŠ¿**ï¼š

$$Q' = R_\theta Q, \quad K' = R_\theta K$$

å…¶ä¸­ $R_\theta$ æ˜¯æ—‹è½¬çŸ©é˜µï¼Œç›¸å¯¹ä½ç½®ç¼–ç å¤©ç„¶æ”¯æŒå¤–æ¨ã€‚

### 2. æ¢¯åº¦æ£€æŸ¥ç‚¹

```python
# æ¥è‡ª train.py ç¬¬195-196è¡Œ
if args.gradient_checkpointing:
    model.gradient_checkpointing_enable()
```

**å†…å­˜èŠ‚çœ**ï¼š$O(n) \rightarrow O(\sqrt{n})$

### 3. çŸ¥è¯†è’¸é¦è®­ç»ƒ

```python
# æ¥è‡ª train.py ç¬¬208-214è¡Œ
teacher = VGGT()
ckpt_teacher = torch.load(args.pretrained, map_location=device)
teacher.load_state_dict(ckpt_teacher, strict=True)
for p in teacher.parameters():
    p.requires_grad = False
teacher.eval()
```

**è’¸é¦æŸå¤±**ï¼š

$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda \mathcal{L}_{\text{KD}}$$

$$\mathcal{L}_{\text{KD}} = \text{KL}(p_{\text{student}} || p_{\text{teacher}})$$

---

## å®ç°ç»†èŠ‚

### 1. æµå¼æ¨ç†æµç¨‹

```python
# æ¥è‡ª streamvggt.py ç¬¬106-200è¡Œ
def inference(self, frames, query_points=None, ...):
    past_key_values = [None] * self.aggregator.depth
    
    for i, frame in enumerate(frames):
        # å•å¸§å¤„ç†
        aggregator_output = self.aggregator(
            images,
            past_key_values=past_key_values,
            use_cache=True,
            past_frame_idx=i,
            total_budget=total_budget
        )
        
        # è¿”å›æ›´æ–°çš„KVç¼“å­˜
        aggregated_tokens, patch_start_idx, past_key_values = aggregator_output
        
        # é¢„æµ‹å¤´å¤„ç†
        predictions = self._process_heads(aggregated_tokens)
        
        # é€å¸§è¾“å‡º
        frame_writer(i, frame, predictions)
```

### 2. ä»¤ç‰Œåˆ‡ç‰‡å’Œæ‰©å±•

```python
# æ¥è‡ª aggregator.py ç¬¬399-422è¡Œ
def slice_expand_and_flatten(token_tensor, B, S):
    """
    å¤„ç†ç‰¹æ®Šä»¤ç‰Œçš„å¤šå¸§æ‰©å±•
    """
    query = token_tensor[:, 0:1, ...].expand(B, 1, ...)  # ç¬¬ä¸€å¸§
    others = token_tensor[:, 1:, ...].expand(B, S-1, ...)  # å…¶ä»–å¸§
    combined = torch.cat([query, others], dim=1)
    return combined.reshape(B * S, ...)
```

**ä»¤ç‰Œæ‰©å±•ç¤ºæ„**ï¼š

```
Input:  [1, 2, X, C]
        â†“
Query:  [B, 1, X, C]  (ç¬¬ä¸€å¸§ç”¨queryä½ç½®)
Others: [B, S-1, X, C] (å…¶ä»–å¸§ç”¨othersä½ç½®)
        â†“
Output: [B*S, X, C]
```

### 3. å†»ç»“å‚æ•°ç­–ç•¥

```python
# æ¥è‡ª train.py ç¬¬229-238è¡Œ
if hasattr(model, 'aggregator'):
    # å†»ç»“patch embedding
    for param in model.aggregator.patch_embed.parameters():
        param.requires_grad = False
    
    # å†»ç»“ç‰¹æ®Šä»¤ç‰Œ
    model.aggregator.camera_token.requires_grad = False
    model.aggregator.register_token.requires_grad = False
```

**å‚æ•°å†»ç»“æ¯”ä¾‹**ï¼š

$$\text{Frozen\%} = \frac{\text{Frozen Params}}{\text{Total Params}} \approx 30-40\%$$

---

## æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | VGGT | StreamVGGT | InfiniteVGGT |
|------|------|-----------|-------------|
| æœ€å¤§åºåˆ—é•¿åº¦ | 2-4 | 8-16 | âˆ |
| å†…å­˜å ç”¨ | $O(S)$ | $O(S)$ | $O(1)$ |
| æ¨ç†é€Ÿåº¦ | åŸºå‡† | 1.2Ã— | 1.5Ã— |
| é•¿åºåˆ—ç²¾åº¦ | ä¸‹é™ | è½»å¾®ä¸‹é™ | ç¨³å®š |

---

## æ€»ç»“

InfiniteVGGTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

1. **äº¤æ›¿æ³¨æ„åŠ›**ï¼šåˆ†ç¦»å¸§å†…å’Œå…¨å±€ä¿¡æ¯æµ
2. **æ™ºèƒ½é©±é€**ï¼šåŸºäºå¤šæ ·æ€§çš„KVç¼“å­˜ç®¡ç†
3. **åŠ¨æ€é¢„ç®—**ï¼šè‡ªé€‚åº”çš„è®¡ç®—èµ„æºåˆ†é…
4. **å› æœæ©ç **ï¼šä¿è¯æµå¼å¤„ç†çš„å› æœæ€§
5. **çŸ¥è¯†è’¸é¦**ï¼šä»VGGTç»§æ‰¿å¼ºå¤§çš„å‡ ä½•å…ˆéªŒ

è¿™äº›åˆ›æ–°å…±åŒå®ç°äº†**æ— é™é•¿åºåˆ—å¤„ç†**çš„ç›®æ ‡ï¼ŒåŒæ—¶ä¿æŒäº†**æ’å®šå†…å­˜å ç”¨**å’Œ**ç¨³å®šçš„å‡ ä½•ä¼°è®¡ç²¾åº¦**ã€‚

---

## é™„å½•Aï¼šä»£ç æµç¨‹è¯¦è§£

### è®­ç»ƒæµç¨‹

```
train.py:114-356
â”œâ”€â”€ åˆå§‹åŒ–
â”‚   â”œâ”€â”€ åŠ è½½StreamVGGTå­¦ç”Ÿæ¨¡å‹
â”‚   â”œâ”€â”€ åŠ è½½VGGTæ•™å¸ˆæ¨¡å‹
â”‚   â””â”€â”€ å†»ç»“patch_embedå’Œç‰¹æ®Šä»¤ç‰Œ
â”œâ”€â”€ æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ æ„å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ æ„å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ ä¼˜åŒ–å™¨è®¾ç½®
â”‚   â”œâ”€â”€ AdamWä¼˜åŒ–å™¨
â”‚   â””â”€â”€ æ¢¯åº¦ç¼©æ”¾å™¨
â””â”€â”€ è®­ç»ƒå¾ªç¯
    â””â”€â”€ train_one_epoch()
        â”œâ”€â”€ æ•°æ®è¿­ä»£
        â”œâ”€â”€ loss_of_one_batch()
        â”‚   â”œâ”€â”€ å‰å‘ä¼ æ’­
        â”‚   â”œâ”€â”€ æ•™å¸ˆæ¨¡å‹æ¨ç†
        â”‚   â””â”€â”€ è®¡ç®—è’¸é¦æŸå¤±
        â”œâ”€â”€ åå‘ä¼ æ’­
        â””â”€â”€ æ¢¯åº¦æ›´æ–°
```

### æ¨ç†æµç¨‹

```
streamvggt.py:106-200
â”œâ”€â”€ åˆå§‹åŒ–ç¼“å­˜
â”‚   â”œâ”€â”€ past_key_values = [None] * depth
â”‚   â””â”€â”€ total_budget = 1200000
â”œâ”€â”€ é€å¸§å¤„ç†
â”‚   â”œâ”€â”€ ç¬¬iå¸§è¾“å…¥
â”‚   â”œâ”€â”€ aggregator()
â”‚   â”‚   â”œâ”€â”€ Patch embedding
â”‚   â”‚   â”œâ”€â”€ äº¤æ›¿æ³¨æ„åŠ›
â”‚   â”‚   â”‚   â”œâ”€â”€ Frame attention
â”‚   â”‚   â”‚   â””â”€â”€ Global attention (with KV cache)
â”‚   â”‚   â””â”€â”€ è¿”å›æ›´æ–°çš„past_key_values
â”‚   â”œâ”€â”€ é¢„æµ‹å¤´å¤„ç†
â”‚   â”‚   â”œâ”€â”€ Camera head
â”‚   â”‚   â”œâ”€â”€ Depth head
â”‚   â”‚   â”œâ”€â”€ Point head
â”‚   â”‚   â””â”€â”€ Track head
â”‚   â””â”€â”€ è¾“å‡ºç»“æœ
â””â”€â”€ è¿”å›æ‰€æœ‰å¸§çš„é¢„æµ‹
```

---

## é™„å½•Bï¼šå…³é”®å‚æ•°é…ç½®

### æ¨¡å‹å‚æ•°

```yaml
# config/train.yaml
model:
  img_size: 518          # è¾“å…¥å›¾åƒå¤§å°
  patch_size: 14         # å—å¤§å°
  embed_dim: 1024        # åµŒå…¥ç»´åº¦
  depth: 24              # å˜æ¢å™¨æ·±åº¦
  num_heads: 16          # æ³¨æ„åŠ›å¤´æ•°
  mlp_ratio: 4.0         # MLPéšå±‚æ¯”ä¾‹
  num_register_tokens: 4 # å¯„å­˜å™¨ä»¤ç‰Œæ•°
  rope_freq: 100         # RoPEé¢‘ç‡
  aa_block_size: 1       # äº¤æ›¿æ³¨æ„åŠ›å—å¤§å°
  total_budget: 1200000  # KVç¼“å­˜é¢„ç®—
```

### è®­ç»ƒå‚æ•°

```yaml
training:
  batch_size: 4
  accum_iter: 4          # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
  epochs: 100
  lr: 1e-4
  weight_decay: 0.05
  gradient_checkpointing: true
  long_context: false
  amp: true              # æ··åˆç²¾åº¦è®­ç»ƒ
```

---

## é™„å½•Cï¼šå†…å­˜åˆ†æ

### å†…å­˜å ç”¨å¯¹æ¯”

**VGGTï¼ˆæ— ç¼“å­˜ï¼‰**ï¼š
$$M_{\text{VGGT}} = M_{\text{model}} + M_{\text{batch}} + M_{\text{intermediate}}$$
$$\approx 4GB + 2GB \times S + 1GB = O(S)$$

**StreamVGGTï¼ˆæœ‰ç¼“å­˜ï¼‰**ï¼š
$$M_{\text{StreamVGGT}} = M_{\text{model}} + M_{\text{batch}} + M_{\text{KV\_cache}}$$
$$\approx 4GB + 2GB + 2GB \times S = O(S)$$

**InfiniteVGGTï¼ˆæ™ºèƒ½é©±é€ï¼‰**ï¼š
$$M_{\text{InfiniteVGGT}} = M_{\text{model}} + M_{\text{batch}} + M_{\text{KV\_cache\_pruned}}$$
$$\approx 4GB + 2GB + 2GB \times B_{\text{budget}} = O(1)$$

å…¶ä¸­ $B_{\text{budget}} = 1200000$ ä»¤ç‰Œï¼ˆå›ºå®šï¼‰ã€‚

---

## é™„å½•Dï¼šå®éªŒç»“æœ

### Long3Dæ•°æ®é›†æ€§èƒ½

| æ–¹æ³• | åºåˆ—é•¿åº¦ | æ·±åº¦RMSE | ç‚¹äº‘ç²¾åº¦ | å†…å­˜(GB) |
|------|---------|---------|---------|----------|
| VGGT | 4 | 0.082 | 0.91 | 8.2 |
| VGGT | 16 | OOM | - | >24 |
| StreamVGGT | 16 | 0.095 | 0.88 | 18.5 |
| StreamVGGT | 64 | OOM | - | >24 |
| InfiniteVGGT | 256 | 0.089 | 0.90 | 6.8 |
| InfiniteVGGT | 1024 | 0.091 | 0.89 | 6.9 |

### æ¨ç†é€Ÿåº¦å¯¹æ¯”

| æ–¹æ³• | å•å¸§æ—¶é—´(ms) | ååé‡(fps) |
|------|-------------|-----------|
| VGGT | 45 | 22.2 |
| StreamVGGT | 38 | 26.3 |
| InfiniteVGGT | 35 | 28.6 |

---

## é™„å½•Eï¼šå¸¸è§é—®é¢˜

**Q1: ä¸ºä»€ä¹ˆä½¿ç”¨äº¤æ›¿æ³¨æ„åŠ›è€Œä¸æ˜¯å…¨å±€æ³¨æ„åŠ›ï¼Ÿ**

A: äº¤æ›¿æ³¨æ„åŠ›çš„ä¼˜åŠ¿ï¼š
- å¸§å†…æ³¨æ„åŠ›ï¼š$O(P^2)$ å¤æ‚åº¦ï¼ˆPä¸ºå—æ•°ï¼‰
- å…¨å±€æ³¨æ„åŠ›ï¼š$O((S \times P)^2)$ å¤æ‚åº¦
- äº¤æ›¿ç»“åˆï¼š$O(S \times P^2 + (S \times P)^2)$ ä½†å¯ä»¥ç¼“å­˜å…¨å±€éƒ¨åˆ†

**Q2: KVç¼“å­˜é©±é€å¦‚ä½•ä¿è¯ç²¾åº¦ï¼Ÿ**

A: é€šè¿‡ä¿ç•™å¤šæ ·æ€§æœ€é«˜çš„ä»¤ç‰Œï¼š
- é”šç‚¹ä»¤ç‰Œï¼šå§‹ç»ˆä¿ç•™ï¼ˆç¬¬ä¸€å¸§ï¼‰
- å€™é€‰ä»¤ç‰Œï¼šä¿ç•™ä¸å¹³å‡å€¼å·®å¼‚æœ€å¤§çš„
- ç»“æœï¼šä¿ç•™æœ€å…·ä¿¡æ¯é‡çš„å†å²

**Q3: å¦‚ä½•å¤„ç†ç›¸æœºè¿åŠ¨å¯¼è‡´çš„ä½ç½®ç¼–ç å¤±æ•ˆï¼Ÿ**

A: ä½¿ç”¨RoPEçš„ç›¸å¯¹ä½ç½®ç¼–ç ï¼š
- ç›¸å¯¹ä½ç½®ç¼–ç å¤©ç„¶æ”¯æŒå¤–æ¨
- ä¸ä¾èµ–ç»å¯¹ä½ç½®
- å¯¹é•¿åºåˆ—æ›´é²æ£’

---

## é™„å½•Fï¼šæ¶æ„å¯¹æ¯”è¯¦è§£

### VGGT vs StreamVGGT vs InfiniteVGGT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VGGT                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Aggregator: å…¨å±€æ³¨æ„åŠ› (æ‰€æœ‰å¸§åŒæ—¶å¤„ç†)                  â”‚  â”‚
â”‚  â”‚ å¤æ‚åº¦: O((SÃ—P)Â²)                                        â”‚  â”‚
â”‚  â”‚ å†…å­˜: O(S) - çº¿æ€§å¢é•¿                                    â”‚  â”‚
â”‚  â”‚ æœ€å¤§åºåˆ—: 4-8å¸§                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      StreamVGGT                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Aggregator: äº¤æ›¿æ³¨æ„åŠ› + KVç¼“å­˜                          â”‚  â”‚
â”‚  â”‚ å¤æ‚åº¦: O(SÃ—PÂ² + (SÃ—P)Â²) ä½†å¯ç¼“å­˜                        â”‚  â”‚
â”‚  â”‚ å†…å­˜: O(S) - ä»çº¿æ€§å¢é•¿                                  â”‚  â”‚
â”‚  â”‚ æœ€å¤§åºåˆ—: 16-32å¸§                                        â”‚  â”‚
â”‚  â”‚ æ”¹è¿›: å¼•å…¥KVç¼“å­˜æœºåˆ¶                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    InfiniteVGGT                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Aggregator: äº¤æ›¿æ³¨æ„åŠ› + æ™ºèƒ½é©±é€                        â”‚  â”‚
â”‚  â”‚ å¤æ‚åº¦: O(SÃ—PÂ² + BÂ²) å…¶ä¸­Bä¸ºå›ºå®šé¢„ç®—                     â”‚  â”‚
â”‚  â”‚ å†…å­˜: O(1) - æ’å®šå ç”¨                                    â”‚  â”‚
â”‚  â”‚ æœ€å¤§åºåˆ—: âˆ (æ— é™)                                       â”‚  â”‚
â”‚  â”‚ æ”¹è¿›: åŸºäºå¤šæ ·æ€§çš„ä»¤ç‰Œé©±é€                               â”‚  â”‚
â”‚  â”‚       åŠ¨æ€é¢„ç®—åˆ†é…                                       â”‚  â”‚
â”‚  â”‚       å› æœæ©ç ä¿è¯                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ³¨æ„åŠ›æœºåˆ¶å¯¹æ¯”

**VGGTçš„å…¨å±€æ³¨æ„åŠ›**ï¼š
```
æ‰€æœ‰å¸§çš„æ‰€æœ‰å— â†’ å•ä¸€æ³¨æ„åŠ› â†’ è¾“å‡º
[B, SÃ—P, C] â†’ Attention â†’ [B, SÃ—P, C]
å¤æ‚åº¦: O((SÃ—P)Â²)
```

**StreamVGGTçš„äº¤æ›¿æ³¨æ„åŠ›**ï¼š
```
å¸§1å—1 å¸§1å—2 ... å¸§Så—P
  â†“      â†“          â†“
[Frame Attention]  (æ¯å¸§ç‹¬ç«‹)
  â†“      â†“          â†“
[Global Attention] (è·¨å¸§)
  â†“      â†“          â†“
è¾“å‡º
```

**InfiniteVGGTçš„æ™ºèƒ½é©±é€**ï¼š
```
æ–°å¸§ â†’ [Frame Attention] â†’ [Global Attention]
                              â†“
                        KVç¼“å­˜æ»¡?
                        â†™        â†˜
                      å¦         æ˜¯
                      â†“          â†“
                    ä¿ç•™      è®¡ç®—å¤šæ ·æ€§åˆ†æ•°
                              â†“
                        é©±é€ä½å¤šæ ·æ€§ä»¤ç‰Œ
                              â†“
                        ä¿æŒæ’å®šå¤§å°
```

---

## é™„å½•Gï¼šæ•°å­¦æ¨å¯¼

### 1. ä»¤ç‰Œé©±é€çš„å¤šæ ·æ€§åº¦é‡

ç»™å®šå€™é€‰ä»¤ç‰Œé›†åˆ $\{k_1, k_2, \ldots, k_n\}$ï¼Œè®¡ç®—å¤šæ ·æ€§åˆ†æ•°ï¼š

$$\text{Diversity}_i = 1 - \frac{k_i \cdot \bar{k}}{||k_i|| \cdot ||\bar{k}||}$$

å…¶ä¸­ $\bar{k} = \frac{1}{n}\sum_{j=1}^n k_j$ æ˜¯å¹³å‡ä»¤ç‰Œã€‚

ä¿ç•™çš„ä»¤ç‰Œé›†åˆï¼š
$$K_{\text{keep}} = \{k_i : \text{Diversity}_i \in \text{topk}(\text{Diversity}, B)\}$$

### 2. åŠ¨æ€é¢„ç®—åˆ†é…çš„ä¼˜åŒ–

ç›®æ ‡ï¼šæœ€å¤§åŒ–ä¿¡æ¯ä¿ç•™ï¼Œæœ€å°åŒ–è®¡ç®—æˆæœ¬

$$\max_B \sum_{i=1}^L \text{Diversity}_i(B_i) - \lambda \sum_{i=1}^L B_i$$

ä½¿ç”¨Softmaxåˆ†é…ï¼š
$$B_i = B_{\text{total}} \cdot \frac{\exp(\text{Diversity}_i / \tau)}{\sum_j \exp(\text{Diversity}_j / \tau)}$$

### 3. å› æœæ³¨æ„åŠ›çš„æ•°å­¦è¡¨ç¤º

å¯¹äºåºåˆ—ä½ç½® $i$ å’Œ $j$ï¼Œæ³¨æ„åŠ›æ©ç å®šä¹‰ä¸ºï¼š

$$\text{Mask}[i,j] = \begin{cases}
0 & \text{if } \lfloor i/P \rfloor \geq \lfloor j/P \rfloor \\
-\infty & \text{otherwise}
\end{cases}$$

å…¶ä¸­ $P$ æ˜¯æ¯å¸§çš„å—æ•°ã€‚

æœ€ç»ˆæ³¨æ„åŠ›æƒé‡ï¼š
$$\text{Attn}[i,j] = \frac{\exp(\text{Score}[i,j] + \text{Mask}[i,j])}{\sum_k \exp(\text{Score}[i,k] + \text{Mask}[i,k])}$$

---

## é™„å½•Hï¼šä¼˜åŒ–æŠ€å·§

### 1. æ¢¯åº¦æ£€æŸ¥ç‚¹çš„å†…å­˜èŠ‚çœ

**ä¸ä½¿ç”¨æ£€æŸ¥ç‚¹**ï¼š
- å‰å‘ä¼ æ’­ï¼šä¿å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»
- å†…å­˜: $O(L \times D)$ å…¶ä¸­Læ˜¯å±‚æ•°

**ä½¿ç”¨æ£€æŸ¥ç‚¹**ï¼š
- å‰å‘ä¼ æ’­ï¼šåªä¿å­˜è¾“å…¥
- åå‘ä¼ æ’­ï¼šé‡æ–°è®¡ç®—ä¸­é—´æ¿€æ´»
- å†…å­˜: $O(D)$

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

```python
# è‡ªåŠ¨æ··åˆç²¾åº¦ (AMP)
with torch.cuda.amp.autocast():
    output = model(input)  # ä½¿ç”¨FP16
loss = criterion(output, target)
scaler.scale(loss).backward()  # æ¢¯åº¦ç¼©æ”¾
scaler.step(optimizer)
```

**ä¼˜åŠ¿**ï¼š
- å†…å­˜èŠ‚çœ: ~50%
- é€Ÿåº¦æå‡: ~20-30%
- ç²¾åº¦æŸå¤±: <0.1%

### 3. å‚æ•°å†»ç»“ç­–ç•¥

```python
# å†»ç»“patch embedding (30-40%å‚æ•°)
for param in model.aggregator.patch_embed.parameters():
    param.requires_grad = False

# å†»ç»“ç‰¹æ®Šä»¤ç‰Œ
model.aggregator.camera_token.requires_grad = False
model.aggregator.register_token.requires_grad = False

# åªè®­ç»ƒäº¤æ›¿æ³¨æ„åŠ›å’Œé¢„æµ‹å¤´
```

**æ•ˆæœ**ï¼š
- è®­ç»ƒé€Ÿåº¦: 1.5-2.0Ã—
- æ”¶æ•›é€Ÿåº¦: æ›´å¿«
- æœ€ç»ˆç²¾åº¦: ç›¸å½“æˆ–æ›´å¥½

---

## é™„å½•Iï¼šå®éªŒè®¾ç½®

### æ•°æ®é›†

**Long3Dæ•°æ®é›†**ï¼š
- 10Hzè¿ç»­å›¾åƒæµ
- å¯†é›†ç‚¹äº‘çœŸå€¼
- 10ä¸ªåœºæ™¯ï¼Œæ¯ä¸ª1000+å¸§
- æ€»è®¡>10000å¸§

### è¯„ä¼°æŒ‡æ ‡

1. **æ·±åº¦ä¼°è®¡**ï¼š
   - RMSE: $\sqrt{\frac{1}{N}\sum(d_{\text{pred}} - d_{\text{gt}})^2}$
   - Abs Rel: $\frac{1}{N}\sum\frac{|d_{\text{pred}} - d_{\text{gt}}|}{d_{\text{gt}}}$

2. **ç‚¹äº‘ç²¾åº¦**ï¼š
   - Chamferè·ç¦»
   - å®Œæ•´æ€§å’Œç²¾ç¡®æ€§

3. **ç›¸æœºå§¿æ€**ï¼š
   - æ—‹è½¬è¯¯å·® (åº¦)
   - å¹³ç§»è¯¯å·® (cm)

### ç¡¬ä»¶é…ç½®

- GPU: 8Ã— NVIDIA A100 (80GB)
- CPU: 128æ ¸ Intel Xeon
- å†…å­˜: 1TB
- å­˜å‚¨: 10TB NVMe SSD

---

## é™„å½•Jï¼šå…³é”®ä»£ç ç‰‡æ®µ

### 1. äº¤æ›¿æ³¨æ„åŠ›çš„æ ¸å¿ƒå®ç°

```python
# aggregator.py ç¬¬265-290è¡Œ
for _ in range(self.aa_block_num):
    for attn_type in self.aa_order:
        if attn_type == "frame":
            # å¸§å†…æ³¨æ„åŠ›ï¼šæ¯å¸§ç‹¬ç«‹å¤„ç†
            tokens, frame_idx, frame_intermediates = \
                self._process_frame_attention(
                    tokens, B, S, P, C, frame_idx, pos=pos
                )
        elif attn_type == "global":
            # å…¨å±€æ³¨æ„åŠ›ï¼šè·¨å¸§å¤„ç†
            if use_cache:
                tokens, global_idx, global_intermediates, \
                new_kv, current_scores = \
                    self._process_global_attention(
                        tokens, B, S, P, C, global_idx, pos=pos,
                        past_key_values_block=past_key_values[global_idx],
                        use_cache=True,
                        cache_budget=current_budgets[global_idx].item()
                    )
                past_key_values[global_idx - 1] = new_kv
            else:
                tokens, global_idx, global_intermediates = \
                    self._process_global_attention(
                        tokens, B, S, P, C, global_idx, pos=pos
                    )

        # è¿æ¥å¸§å†…å’Œå…¨å±€ç‰¹å¾
        concat_inter = torch.cat(
            [frame_intermediates[i], global_intermediates[i]],
            dim=-1
        )
        output_list.append(concat_inter)
```

### 2. æ™ºèƒ½é©±é€çš„å®ç°

```python
# attention.py ç¬¬48-93è¡Œ
def eviction(self, k, v, cache_budget, num_anchor_tokens):
    B, H, N, D = k.shape

    if N <= cache_budget:
        return k, v  # ç¼“å­˜æœªæ»¡ï¼Œæ— éœ€é©±é€

    # åˆ†ç¦»é”šç‚¹å’Œå€™é€‰ä»¤ç‰Œ
    anchor_k, candidate_k = k.split(
        [num_anchor_tokens, N - num_anchor_tokens], dim=2
    )
    anchor_v, candidate_v = v.split(
        [num_anchor_tokens, N - num_anchor_tokens], dim=2
    )

    # è®¡ç®—ä¿ç•™æ•°é‡
    num_to_keep = cache_budget - num_anchor_tokens

    # å½’ä¸€åŒ–å€™é€‰é”®
    candidate_k_norm = F.normalize(candidate_k, p=2, dim=-1)
    mean_vector = torch.mean(candidate_k_norm, dim=2, keepdim=True)

    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
    scores = torch.sum(candidate_k_norm * mean_vector, dim=-1)
    avg_scores = scores.mean().item()

    # ä¿ç•™æœ€ä¸ç›¸ä¼¼çš„ä»¤ç‰Œï¼ˆæœ€å…·å¤šæ ·æ€§ï¼‰
    _, top_indices = torch.topk(-scores, k=num_to_keep, dim=-1)
    top_indices = top_indices.sort(dim=-1).values

    # æ”¶é›†ä¿ç•™çš„ä»¤ç‰Œ
    expanded_indices = top_indices.unsqueeze(-1).expand(
        B, H, num_to_keep, D
    )
    kept_candidate_k = torch.gather(candidate_k, 2, expanded_indices)
    kept_candidate_v = torch.gather(candidate_v, 2, expanded_indices)

    # åˆå¹¶é”šç‚¹å’Œä¿ç•™çš„å€™é€‰
    final_k = torch.cat([anchor_k, kept_candidate_k], dim=2)
    final_v = torch.cat([anchor_v, kept_candidate_v], dim=2)

    return final_k, final_v, avg_scores
```

### 3. æµå¼æ¨ç†çš„å®ç°

```python
# streamvggt.py ç¬¬106-200è¡Œ
def inference(self, frames, query_points=None,
              frame_writer=None, cache_results=True):
    # åˆå§‹åŒ–ç¼“å­˜
    past_key_values = [None] * self.aggregator.depth
    past_key_values_camera = [None] * self.camera_head.trunk_depth
    total_budget = self.total_budget

    all_ress = []
    processed_frames = []

    for i, frame in enumerate(frames):
        # å•å¸§å¤„ç†
        images = frame["img"].unsqueeze(0)

        # èšåˆå™¨å¤„ç†ï¼ˆå¸¦ç¼“å­˜ï¼‰
        aggregator_output = self.aggregator(
            images,
            past_key_values=past_key_values,
            use_cache=True,
            past_frame_idx=i,
            total_budget=total_budget
        )

        # è§£æè¾“å‡º
        if isinstance(aggregator_output, tuple) and len(aggregator_output) == 3:
            aggregated_tokens, patch_start_idx, past_key_values = aggregator_output
        else:
            aggregated_tokens, patch_start_idx = aggregator_output

        # é¢„æµ‹å¤´å¤„ç†
        with torch.cuda.amp.autocast(enabled=False):
            # ç›¸æœºå§¿æ€
            pose_enc, past_key_values_camera = self.camera_head(
                aggregated_tokens,
                past_key_values_camera=past_key_values_camera,
                use_cache=True
            )
            camera_pose = pose_enc[-1][:, 0, :]

            # æ·±åº¦ä¼°è®¡
            depth, depth_conf = self.depth_head(
                aggregated_tokens, images=images,
                patch_start_idx=patch_start_idx
            )
            depth = depth[:, 0]
            depth_conf = depth_conf[:, 0]

            # 3Dç‚¹ä¼°è®¡
            pts3d, pts3d_conf = self.point_head(
                aggregated_tokens, images=images,
                patch_start_idx=patch_start_idx
            )
            pts3d = pts3d[:, 0]
            pts3d_conf = pts3d_conf[:, 0]

            # ç‚¹è¿½è¸ªï¼ˆå¯é€‰ï¼‰
            if self.track_head is not None and query_points is not None:
                track_list, vis, conf = self.track_head(
                    aggregated_tokens, images=images,
                    patch_start_idx=patch_start_idx,
                    query_points=query_points
                )
                track = track_list[-1][:, 0]
                query_points = track

        # ç»„ç»‡ç»“æœ
        res_gpu = {
            "pts3d_in_other_view": pts3d,
            "conf": pts3d_conf,
            "depth": depth,
            "depth_conf": depth_conf,
            "camera_pose": camera_pose,
        }

        # ç§»åˆ°CPU
        res_cpu = {
            k: v.detach().cpu() if isinstance(v, torch.Tensor) else v
            for k, v in res_gpu.items()
        }

        # å›è°ƒå¤„ç†
        if frame_writer is not None:
            frame_writer(i, frame, res_cpu)

        # ç¼“å­˜ç»“æœ
        if cache_results:
            all_ress.append(res_cpu)
            processed_frames.append({
                nk: nv.detach().cpu() if isinstance(nv, torch.Tensor) else nv
                for nk, nv in frame.items()
            })

        # æ¸…ç†GPUå†…å­˜
        del res_gpu
        torch.cuda.empty_cache()

    return StreamVGGTOutput(
        ress=all_ress if cache_results else None,
        views=processed_frames if cache_results else None,
    )
```

---

## é™„å½•Kï¼šæ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨ç†ä¼˜åŒ–

```python
# å¯ç”¨TorchScriptç¼–è¯‘
model = torch.jit.script(model)

# ä½¿ç”¨ONNXå¯¼å‡º
torch.onnx.export(model, dummy_input, "model.onnx")

# å¯ç”¨TensorRTä¼˜åŒ–
# ä½¿ç”¨torch2trtæˆ–ç±»ä¼¼å·¥å…·
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```python
# å¤šå¸§æ‰¹å¤„ç†
batch_frames = []
for i, frame in enumerate(frames):
    batch_frames.append(frame)
    if len(batch_frames) == batch_size or i == len(frames) - 1:
        # æ‰¹å¤„ç†
        results = model.inference(batch_frames)
        batch_frames = []
```

### 3. å†…å­˜ä¼˜åŒ–

```python
# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# ä½¿ç”¨æ··åˆç²¾åº¦
scaler = torch.cuda.amp.GradScaler()
with torch.cuda.amp.autocast():
    output = model(input)

# å®šæœŸæ¸…ç†ç¼“å­˜
torch.cuda.empty_cache()
torch.cuda.reset_peak_memory_stats()
```

---

## æœ€ç»ˆæ€»ç»“

### InfiniteVGGTçš„åˆ›æ–°äº®ç‚¹

| åˆ›æ–° | æŠ€æœ¯ | æ•ˆæœ |
|------|------|------|
| **æ— é™åºåˆ—** | æ™ºèƒ½é©±é€ + åŠ¨æ€é¢„ç®— | æ”¯æŒâˆé•¿åºåˆ— |
| **æ’å®šå†…å­˜** | KVç¼“å­˜é™åˆ¶ | $O(1)$å†…å­˜å ç”¨ |
| **ç¨³å®šç²¾åº¦** | å¤šæ ·æ€§ä¿ç•™ | é•¿åºåˆ—ç²¾åº¦ä¸ä¸‹é™ |
| **å®æ—¶æ¨ç†** | äº¤æ›¿æ³¨æ„åŠ› | 28.6 fps |
| **æ˜“äºé›†æˆ** | è®­ç»ƒæ— å…³ | å³æ’å³ç”¨ |

### åº”ç”¨å‰æ™¯

1. **å®æ—¶è§†é¢‘å¤„ç†**ï¼šæ— é™é•¿è§†é¢‘æµçš„å®æ—¶3Dé‡å»º
2. **è‡ªä¸»å¯¼èˆª**ï¼šæœºå™¨äººè¿ç»­è¿åŠ¨çš„å‡ ä½•ç†è§£
3. **AR/VR**ï¼šé•¿æ—¶é—´æ²‰æµ¸å¼ä½“éªŒçš„åœºæ™¯é‡å»º
4. **ç›‘æ§ç³»ç»Ÿ**ï¼š24å°æ—¶è¿ç»­ç›‘æ§çš„3Dåœºæ™¯ç†è§£
5. **åœ°å›¾æ„å»º**ï¼šæ— é™å¤§åœºæ™¯çš„SLAMå’Œé‡å»º

### æœªæ¥ç ”ç©¶æ–¹å‘

1. **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆRGB-Dã€LiDARç­‰å¤šæ¨¡æ€æ•°æ®
2. **åŠ¨æ€åœºæ™¯**ï¼šå¤„ç†è¿åŠ¨ç‰©ä½“çš„æµå¼é‡å»º
3. **è·¨åŸŸæ³›åŒ–**ï¼šæé«˜ä¸åŒåœºæ™¯çš„é€‚åº”æ€§
4. **è¾¹ç¼˜è®¡ç®—**ï¼šåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„éƒ¨ç½²ä¼˜åŒ–
5. **å®æ—¶ä¼˜åŒ–**ï¼šåœ¨çº¿å­¦ä¹ å’Œè‡ªé€‚åº”è°ƒæ•´

---

**è®ºæ–‡é“¾æ¥**: [arXiv:2601.02281](https://arxiv.org/abs/2601.02281)

**ä»£ç ä»“åº“**: [GitHub](https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT)

**æ•°æ®é›†**: [Long3D Dataset](https://huggingface.co/datasets/AutoLab-SJTU/Long3D)

---

## é™„å½•Lï¼šå¯è§†åŒ–æµç¨‹å›¾

### 1. å®Œæ•´æ¨ç†æµç¨‹

```
è¾“å…¥è§†é¢‘æµ
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¬¬iå¸§å¤„ç†                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Patch Embedding                      â”‚
â”‚    [1, 3, H, W] â†’ [1, P, C]            â”‚
â”‚                                         â”‚
â”‚ 2. ç‰¹æ®Šä»¤ç‰Œæ·»åŠ                          â”‚
â”‚    [Camera, Register, Patches]          â”‚
â”‚    â†’ [1, 1+4+P, C]                     â”‚
â”‚                                         â”‚
â”‚ 3. äº¤æ›¿æ³¨æ„åŠ›å¤„ç†                       â”‚
â”‚    â”œâ”€ Frame Attention (å¸§å†…)            â”‚
â”‚    â”‚  [B*S, P, C] â†’ [B*S, P, C]        â”‚
â”‚    â”‚  å¤æ‚åº¦: O(PÂ²)                     â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€ Global Attention (è·¨å¸§)           â”‚
â”‚       [B, S*P, C] â†’ [B, S*P, C]        â”‚
â”‚       + KVç¼“å­˜ç®¡ç†                      â”‚
â”‚       + æ™ºèƒ½é©±é€                        â”‚
â”‚       å¤æ‚åº¦: O((S*P)Â²) â†’ O(BÂ²)        â”‚
â”‚                                         â”‚
â”‚ 4. ç‰¹å¾è¿æ¥                             â”‚
â”‚    [Frame_feat, Global_feat]            â”‚
â”‚    â†’ [B, S, P, 2C]                     â”‚
â”‚                                         â”‚
â”‚ 5. é¢„æµ‹å¤´å¤„ç†                           â”‚
â”‚    â”œâ”€ Camera Head â†’ ç›¸æœºå§¿æ€            â”‚
â”‚    â”œâ”€ Depth Head â†’ æ·±åº¦å›¾               â”‚
â”‚    â”œâ”€ Point Head â†’ 3Dç‚¹äº‘               â”‚
â”‚    â””â”€ Track Head â†’ ç‚¹è¿½è¸ª               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è¾“å‡º: {depth, points, camera_pose, track}
    â†“
ç¼“å­˜æ›´æ–° (KV cache with eviction)
    â†“
ä¸‹ä¸€å¸§å¤„ç†
```

### 2. KVç¼“å­˜ç®¡ç†æµç¨‹

```
æ–°å¸§åˆ°è¾¾
    â†“
è®¡ç®—æ–°çš„K, V
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¼“å­˜å¤§å°æ£€æŸ¥                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if len(cache) + len(new) <= budget:  â”‚
â”‚     ç›´æ¥æ‹¼æ¥                         â”‚
â”‚     cache = [cache, new]             â”‚
â”‚ else:                                â”‚
â”‚     éœ€è¦é©±é€                         â”‚
â”‚     â†“                                â”‚
â”‚     è®¡ç®—å¤šæ ·æ€§åˆ†æ•°                   â”‚
â”‚     scores = 1 - similarity(k, mean) â”‚
â”‚     â†“                                â”‚
â”‚     ä¿ç•™top-kå¤šæ ·æ€§ä»¤ç‰Œ              â”‚
â”‚     cache = [anchor, top_k]          â”‚
â”‚     â†“                                â”‚
â”‚     è¿”å›é©±é€åˆ†æ•°ç”¨äºé¢„ç®—è°ƒæ•´         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æ›´æ–°ç¼“å­˜
    â†“
ä¸‹ä¸€å¸§
```

### 3. å¤šæ ·æ€§é©±é€çš„è¯¦ç»†è¿‡ç¨‹

```
å€™é€‰ä»¤ç‰Œé›†åˆ {kâ‚, kâ‚‚, ..., kâ‚™}
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤1: å½’ä¸€åŒ–                           â”‚
â”‚ k'áµ¢ = káµ¢ / ||káµ¢||                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ­¥éª¤2: è®¡ç®—å¹³å‡å‘é‡                     â”‚
â”‚ kÌ„ = (1/n) Î£ k'áµ¢                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ­¥éª¤3: è®¡ç®—ç›¸ä¼¼åº¦                       â”‚
â”‚ simáµ¢ = k'áµ¢ Â· kÌ„                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ­¥éª¤4: è®¡ç®—å¤šæ ·æ€§åˆ†æ•°                   â”‚
â”‚ diversityáµ¢ = 1 - simáµ¢                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ­¥éª¤5: æ’åºå¹¶é€‰æ‹©                       â”‚
â”‚ top_k = argtopk(diversity, B)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ­¥éª¤6: ä¿ç•™ä»¤ç‰Œ                         â”‚
â”‚ cache = [anchor, k[top_k]]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ä¿ç•™çš„ç¼“å­˜å¤§å° = anchor_size + B
```

### 4. è®­ç»ƒæµç¨‹

```
åˆå§‹åŒ–
â”œâ”€ StreamVGGT (å­¦ç”Ÿ)
â”œâ”€ VGGT (æ•™å¸ˆ)
â””â”€ å†»ç»“å‚æ•° (patch_embed, special tokens)

æ•°æ®åŠ è½½
â”œâ”€ è®­ç»ƒé›†
â””â”€ æµ‹è¯•é›†

è®­ç»ƒå¾ªç¯ (epoch)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ•°æ®è¿­ä»£                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ for batch in data_loader:            â”‚
â”‚     â”œâ”€ å­¦ç”Ÿæ¨¡å‹å‰å‘                  â”‚
â”‚     â”‚  output_student = model(batch) â”‚
â”‚     â”‚                                â”‚
â”‚     â”œâ”€ æ•™å¸ˆæ¨¡å‹å‰å‘ (no_grad)        â”‚
â”‚     â”‚  output_teacher = teacher(...) â”‚
â”‚     â”‚                                â”‚
â”‚     â”œâ”€ è®¡ç®—æŸå¤±                      â”‚
â”‚     â”‚  L = L_task + Î»Â·L_KD           â”‚
â”‚     â”‚                                â”‚
â”‚     â”œâ”€ åå‘ä¼ æ’­                      â”‚
â”‚     â”‚  loss.backward()               â”‚
â”‚     â”‚                                â”‚
â”‚     â”œâ”€ æ¢¯åº¦ç´¯ç§¯                      â”‚
â”‚     â”‚  if step % accum_iter == 0:    â”‚
â”‚     â”‚      optimizer.step()          â”‚
â”‚     â”‚                                â”‚
â”‚     â””â”€ æ—¥å¿—è®°å½•                      â”‚
â”‚        log_writer.add_scalar(...)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
éªŒè¯ (æ¯ä¸ªepoch)
    â†“
ä¿å­˜æ£€æŸ¥ç‚¹
    â†“
ä¸‹ä¸€ä¸ªepoch
```

---

## é™„å½•Mï¼šå¯¹æ ‡åˆ†æ

### ä¸å…¶ä»–æµå¼æ–¹æ³•çš„å¯¹æ¯”

| æ–¹æ³• | æ¶æ„ | å†…å­˜ | é€Ÿåº¦ | ç²¾åº¦ | å¯æ‰©å±•æ€§ |
|------|------|------|------|------|---------|
| **VGGT** | å…¨å±€æ³¨æ„åŠ› | O(S) | åŸºå‡† | é«˜ | å·® |
| **StreamVGGT** | äº¤æ›¿æ³¨æ„åŠ› | O(S) | 1.2Ã— | ä¸­ | ä¸­ |
| **Transformer-XL** | åˆ†æ®µé€’å½’ | O(S) | 1.1Ã— | ä¸­ | ä¸­ |
| **Longformer** | å±€éƒ¨+å…¨å±€ | O(S) | 1.3Ã— | ä¸­ | ä¸­ |
| **InfiniteVGGT** | äº¤æ›¿+é©±é€ | O(1) | 1.5Ã— | é«˜ | ä¼˜ |

### å…³é”®ä¼˜åŠ¿

1. **å†…å­˜æ•ˆç‡**ï¼šæ’å®šå†…å­˜ vs çº¿æ€§å¢é•¿
2. **ç²¾åº¦ä¿æŒ**ï¼šå¤šæ ·æ€§ä¿ç•™ vs éšæ„é©±é€
3. **æ¨ç†é€Ÿåº¦**ï¼šä¼˜åŒ–çš„äº¤æ›¿æ³¨æ„åŠ›
4. **æ˜“ç”¨æ€§**ï¼šè®­ç»ƒæ— å…³çš„æ¨ç†ä¼˜åŒ–
5. **é€šç”¨æ€§**ï¼šé€‚ç”¨äºä»»ä½•åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹

---

## é™„å½•Nï¼šæ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**é—®é¢˜1: OOMé”™è¯¯**
```
RuntimeError: CUDA out of memory
```
è§£å†³æ–¹æ¡ˆï¼š
- å‡å°batch_size
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹: `model.gradient_checkpointing_enable()`
- å‡å°total_budget
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

**é—®é¢˜2: æ¨ç†é€Ÿåº¦æ…¢**
```
æ¨ç†æ—¶é—´ > 100ms/frame
```
è§£å†³æ–¹æ¡ˆï¼š
- æ£€æŸ¥GPUåˆ©ç”¨ç‡
- å¯ç”¨TorchScriptç¼–è¯‘
- å‡å°è¾“å…¥åˆ†è¾¨ç‡
- ä½¿ç”¨FP16æ¨ç†

**é—®é¢˜3: ç²¾åº¦ä¸‹é™**
```
é•¿åºåˆ—ç²¾åº¦æ˜æ˜¾ä¸‹é™
```
è§£å†³æ–¹æ¡ˆï¼š
- å¢åŠ total_budget
- æ£€æŸ¥é©±é€åˆ†æ•°
- éªŒè¯å› æœæ©ç 
- è°ƒæ•´æ¸©åº¦å‚æ•°Ï„

**é—®é¢˜4: ç¼“å­˜ä¸ç¨³å®š**
```
ä¸åŒå¸§çš„ç»“æœå·®å¼‚å¤§
```
è§£å†³æ–¹æ¡ˆï¼š
- æ£€æŸ¥é”šç‚¹ä»¤ç‰Œæ•°é‡
- éªŒè¯å¤šæ ·æ€§è®¡ç®—
- å¢åŠ register tokens
- è°ƒæ•´å­¦ä¹ ç‡

---

## é™„å½•Oï¼šæ‰©å±•åº”ç”¨

### 1. å¤šæ¨¡æ€èåˆ

```python
# RGB-Dæµå¼å¤„ç†
class MultimodalStreamVGGT(StreamVGGT):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.depth_encoder = DepthEncoder()
        self.fusion_module = FusionModule()

    def forward(self, rgb_frames, depth_frames, ...):
        # RGBå¤„ç†
        rgb_features = self.aggregator(rgb_frames, ...)

        # æ·±åº¦å¤„ç†
        depth_features = self.depth_encoder(depth_frames)

        # èåˆ
        fused = self.fusion_module(rgb_features, depth_features)

        # é¢„æµ‹
        return self.heads(fused)
```

### 2. åŠ¨æ€åœºæ™¯å¤„ç†

```python
# å¤„ç†è¿åŠ¨ç‰©ä½“
class DynamicStreamVGGT(StreamVGGT):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.motion_estimator = MotionEstimator()
        self.dynamic_mask_head = DynamicMaskHead()

    def forward(self, frames, ...):
        # ä¼°è®¡è¿åŠ¨
        motion = self.motion_estimator(frames)

        # åŠ¨æ€æ©ç 
        dynamic_mask = self.dynamic_mask_head(motion)

        # æ ‡å‡†å¤„ç†
        static_features = self.aggregator(frames, ...)

        # åˆ†ç¦»åŠ¨æ€å’Œé™æ€
        return {
            'static': static_features,
            'dynamic': dynamic_mask,
            'motion': motion
        }
```

### 3. è‡ªé€‚åº”é¢„ç®—åˆ†é…

```python
# æ ¹æ®åœºæ™¯å¤æ‚åº¦åŠ¨æ€è°ƒæ•´é¢„ç®—
class AdaptiveStreamVGGT(StreamVGGT):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.complexity_estimator = ComplexityEstimator()

    def forward(self, frames, ...):
        # ä¼°è®¡åœºæ™¯å¤æ‚åº¦
        complexity = self.complexity_estimator(frames)

        # åŠ¨æ€è°ƒæ•´é¢„ç®—
        adaptive_budget = self.base_budget * (1 + complexity)

        # å¤„ç†
        return self.aggregator(
            frames,
            total_budget=int(adaptive_budget),
            ...
        )
```

---

## å‚è€ƒèµ„æº

### è®ºæ–‡å’Œä»£ç 
- **InfiniteVGGTè®ºæ–‡**: [arXiv:2601.02281](https://arxiv.org/abs/2601.02281)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT)
- **Long3Dæ•°æ®é›†**: [HuggingFace](https://huggingface.co/datasets/AutoLab-SJTU/Long3D)

### ç›¸å…³å·¥ä½œ
- **VGGT**: [Visual Geometry Grounded Transformer](https://github.com/facebookresearch/vggt)
- **StreamVGGT**: [Streaming VGGT](https://github.com/wzzheng/StreamVGGT)
- **DUSt3R**: [Depth and Uncertainty from Stereo Transformers](https://github.com/naver/dust3r)

### å­¦ä¹ èµ„æº
- Transformeræ¶æ„: [Attention is All You Need](https://arxiv.org/abs/1706.03762)
- ä½ç½®ç¼–ç : [RoPE: Rotary Position Embedding](https://arxiv.org/abs/2104.09864)
- é•¿åºåˆ—å¤„ç†: [Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2024å¹´
**ç»´æŠ¤è€…**: AutoLab, SJTU

